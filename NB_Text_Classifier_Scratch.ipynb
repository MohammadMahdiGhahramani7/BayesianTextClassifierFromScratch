{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NB_Text_Classifier_Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aYSPh4mOOR6o",
        "SSpIPBKjOep7",
        "spA0nMH4URBe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYSPh4mOOR6o"
      },
      "source": [
        "#My Bayesian Text Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OStXRQh5yHh4"
      },
      "source": [
        "class My_NB_Text_Classifier:\n",
        "\n",
        "  def __init__(self, sens, stop_words):\n",
        "\n",
        "    self.sens = {i.lower():sens[i] for i in sens}\n",
        "    self.stw = stop_words\n",
        "    self.prob_positive = sum(sens.values()) / len(sens)\n",
        "    self.prob_negative = 1 - self.prob_positive\n",
        "    self.positives, self.positive_words_p_hats = {}, {}\n",
        "    self.negatives, self.negative_words_p_hats = {}, {}\n",
        "    self.extra = list(\"!@#$%^&*()./-+~0123456789\")\n",
        "\n",
        "  def _remove_spaces_of_lists(self, words):\n",
        "\n",
        "    while '' in words:\n",
        "\n",
        "      words.pop(words.index(''))\n",
        "\n",
        "    return words\n",
        "\n",
        "  def _clean_and_remove_stop_words_(self, sen):\n",
        "\n",
        "    #Cleaning\n",
        "    for sym in self.extra:\n",
        "\n",
        "      sen = sen.replace(sym, \"\")\n",
        "\n",
        "    #Extract words\n",
        "    words = sen.split(\" \")\n",
        "\n",
        "    #removing stop word\n",
        "    for w in words:\n",
        "\n",
        "      if w in self.stw:\n",
        "\n",
        "        words[words.index(w)] = \"\"\n",
        "\n",
        "    return words\n",
        "\n",
        "  def _add_word_to_pn(self, words, label):\n",
        "\n",
        "    if label:\n",
        "\n",
        "      for w in words:\n",
        "\n",
        "        if w in self.positives:\n",
        "\n",
        "          self.positives[w] += 1\n",
        "\n",
        "        else:\n",
        "\n",
        "          self.positives[w] = 1\n",
        "\n",
        "    else:\n",
        "\n",
        "      for w in words:\n",
        "\n",
        "        if w in self.negatives:\n",
        "\n",
        "          self.negatives[w] += 1\n",
        "\n",
        "        else:\n",
        "\n",
        "          self.negatives[w] = 1\n",
        "\n",
        "  def fit(self):\n",
        "\n",
        "    for key in self.sens:\n",
        "\n",
        "      sentence, label = key, self.sens[key]\n",
        "\n",
        "      words = self._clean_and_remove_stop_words_(sentence)\n",
        "\n",
        "      self._add_word_to_pn(words, label)\n",
        "\n",
        "    self.positives.pop('')\n",
        "    self.negatives.pop('')\n",
        "\n",
        "  def predict(self, new_sen, verbose=True):\n",
        "\n",
        "    positives_copy, negatives_copy = self.positives, self.negatives\n",
        "\n",
        "    new_sen = new_sen.lower()\n",
        "\n",
        "    ws = self._clean_and_remove_stop_words_(new_sen)\n",
        "    \n",
        "    ws = self._remove_spaces_of_lists(ws)\n",
        "\n",
        "    self.being_positive, self.being_negative = 1, 1\n",
        "\n",
        "    #Evaluate of being POSITIVE\n",
        "    for w in ws:\n",
        "\n",
        "      if w not in positives_copy:\n",
        "\n",
        "        positives_copy[w] = 0\n",
        "\n",
        "    #PË†(wk |vj) = (nk + 1) / (n + |Vocabulary|)\n",
        "    positive_length = sum(positives_copy.values())\n",
        "    positive_vocab_length = len(positives_copy.values())\n",
        "\n",
        "    for wp in positives_copy:\n",
        "\n",
        "      self.positive_words_p_hats[wp] = (positives_copy[wp] + 1) / (positive_length + positive_vocab_length)\n",
        "\n",
        "    for w in ws:\n",
        "\n",
        "      self.being_positive *= self.positive_words_p_hats[w]\n",
        "\n",
        "\n",
        "    #Evaluate of being NEGATIVE\n",
        "    for w in ws:\n",
        "\n",
        "      if w not in negatives_copy:\n",
        "\n",
        "        negatives_copy[w] = 0\n",
        "\n",
        "    #PË†(wk |vj) = (nk + 1) / (n + |Vocabulary|)\n",
        "    negative_length = sum(negatives_copy.values())\n",
        "    negative_vocab_length = len(negatives_copy.values())\n",
        "\n",
        "    for wp in negatives_copy:\n",
        "\n",
        "      self.negative_words_p_hats[wp] = (negatives_copy[wp] + 1) / (negative_length + negative_vocab_length)\n",
        "\n",
        "    for w in ws:\n",
        "\n",
        "      self.being_negative *= self.negative_words_p_hats[w]\n",
        "\n",
        "    self.prob_of_being_postive = self.being_positive / (self.being_positive + self.being_negative)\n",
        "    self.prob_of_being_negative = 1 - self.prob_of_being_postive\n",
        "\n",
        "\n",
        "    if self.being_positive > self.being_negative:\n",
        "\n",
        "      if verbose:\n",
        "\n",
        "        print(f\"POSITIVE\\nProbability(positive): {self.prob_of_being_postive:.3f}\\nProbability(negative): {self.prob_of_being_negative:.3f}\")\n",
        "\n",
        "      return 1\n",
        "\n",
        "    else:\n",
        "\n",
        "      if verbose:\n",
        "\n",
        "        print(f\"NEGATIVE\\nProbability(positive): {self.prob_of_being_postive:.3f}\\nProbability(negative): {self.prob_of_being_negative:.3f}\")\n",
        "\n",
        "      return 0"
      ],
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSpIPBKjOep7"
      },
      "source": [
        "#Testing on a Small Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YiJeI0SOgkt"
      },
      "source": [
        "stop_words = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there',\n",
        "              'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they',\n",
        "              'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into',\n",
        "              'of', 'most', 'itself', 'other', 'off', 'is', 'am', 'or', 'who',\n",
        "              'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are',\n",
        "              'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her',\n",
        "              'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above',\n",
        "              'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'when', 'at', 'any',\n",
        "              'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does',\n",
        "              'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can',\n",
        "              'did', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where',\n",
        "              'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom',\n",
        "              'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how',\n",
        "              'further', 'was', 'here', 'than']\n",
        "\n",
        "sens = {\"I am good\":1, \"I am bad\":0, \"You are smArt\":1, \"She is stupid\":0, \"We are fine\":1,\n",
        "        \"Awful result\":0, \"I hate you\":0, \"We are soulmates\":1, \"YoU are GoOd\":1}"
      ],
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ9STVyxOJQc"
      },
      "source": [
        "MNTC = My_NB_Text_Classifier(sens, stop_words)\n",
        "    \n",
        "MNTC.fit()"
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxAaMBbSG5tC",
        "outputId": "2e3dfe7e-fbad-4842-aa3d-e05fb5b4ed9d"
      },
      "source": [
        "MNTC.predict(\"Every tHinG was BAd. How AWFuL iT waS!\")"
      ],
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEGATIVE\n",
            "Probability(positive): 0.154\n",
            "Probability(negative): 0.846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 393
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oyWuRoxP7JD",
        "outputId": "dd412692-abc1-415b-d25b-5177d6f2ab74"
      },
      "source": [
        "MNTC.predict(\"Every tHinG was BAd. How AWFuL iT waS! BUt it was ALSO GOOD\")"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEGATIVE\n",
            "Probability(positive): 0.429\n",
            "Probability(negative): 0.571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV1P4xhZRJ_J",
        "outputId": "2b311d9b-f9ee-43b1-98cd-99a5b1ac1854"
      },
      "source": [
        "MNTC.predict(\"Every tHinG was BAd. How AWFuL iT waS! BUt it was ALSO GOOD. ACTUALLY, The food was FInE\")"
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POSITIVE\n",
            "Probability(positive): 0.721\n",
            "Probability(negative): 0.279\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v36taoXRU4v",
        "outputId": "1d50f00d-5745-47f2-ecc4-bc09333bf368"
      },
      "source": [
        "MNTC.predict(\"Every tHinG was BAd. How AWFuL iT waS! BUt it was ALSO GOOD. ACTUALLY, The food was FInE. The manager was smarT\")"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POSITIVE\n",
            "Probability(positive): 0.911\n",
            "Probability(negative): 0.089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlSPKVyBUCf_"
      },
      "source": [
        "As it can be seen, the more positive words are added, the higher probability for being positive is provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spA0nMH4URBe"
      },
      "source": [
        "#Testing on a Large Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Eiz-80qaRfnW",
        "outputId": "18fb453d-6cde-4669-de94-210733fd7b01"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Restaurant_Reviews.csv\")\n",
        "\n",
        "df.head(5)"
      ],
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {},
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ZEevtqU2Rm"
      },
      "source": [
        "n = int(0.8 * len(df))\n",
        "train_set = {}\n",
        "\n",
        "for idx in range(n):\n",
        "\n",
        "  train_set[df['Review'][idx]] = df['Liked'][idx]"
      ],
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgDq7aDdWHCZ"
      },
      "source": [
        "test_set = {}\n",
        "\n",
        "for idx in range(n, len(df)):\n",
        "\n",
        "  test_set[df['Review'][idx]] = df['Liked'][idx]"
      ],
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQsU5oMtWWda",
        "outputId": "b7455076-0ab3-4b75-e349-12d2dba96d06"
      },
      "source": [
        "print(len(train_set), len(test_set))"
      ],
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiXRP06uUvnF"
      },
      "source": [
        "MNTC = My_NB_Text_Classifier(train_set, stop_words)\n",
        "    \n",
        "MNTC.fit()"
      ],
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23c4TY7BWrQE"
      },
      "source": [
        "predicted_labels = []\n",
        "\n",
        "for s in test_set:\n",
        "\n",
        "  predicted_labels.append(MNTC.predict(s, verbose=False))"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZgCG2qAVut3"
      },
      "source": [
        "real_labels = list(test_set.values())"
      ],
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Knj1z3XiXpcA",
        "outputId": "4e1406f9-d28e-4b8d-aaa5-685bf4c4e343"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import emojis\n",
        "\n",
        "print(emojis.encode(f\"Accuracy: {100 * accuracy_score(predicted_labels, real_labels):.1f}% :sunglasses:\"))"
      ],
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.5% ðŸ˜Ž\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0Y0oIona-7j",
        "outputId": "c590d30b-4896-449a-fd82-6c65b4231603"
      },
      "source": [
        "sentence = \"It was good\"\n",
        "\n",
        "_ = MNTC.predict(sentence)"
      ],
      "execution_count": 448,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POSITIVE\n",
            "Probability(positive): 0.747\n",
            "Probability(negative): 0.253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvi81i--bG7B",
        "outputId": "8943f0c5-b694-4c5d-c97a-79a4f0bab885"
      },
      "source": [
        "sentence = \"It was not bad\"\n",
        "\n",
        "_ = MNTC.predict(sentence)#As mentioned in the class, this method cannot classify \"It was not bad\" correctly."
      ],
      "execution_count": 451,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEGATIVE\n",
            "Probability(positive): 0.014\n",
            "Probability(negative): 0.986\n"
          ]
        }
      ]
    }
  ]
}